{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 QDA\n",
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.load('data/data1d.npy')\n",
    "labels = np.load('data/labels1d.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Trees and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "pts = np.load('data/data1d.npy')\n",
    "labels = np.load('data/labels1d.npy')\n",
    "\n",
    "# TODO: Sort the points to easily split them\n",
    "\n",
    "# TODO: Implement or find implementation for Gini impurity, entropy and misclassifcation rate\n",
    "\n",
    "def probabilities(partition):\n",
    "    # divide counts by size of dataset to get cluster probabilites\n",
    "    return np.unique(partition, return_counts=True)[1] / len(partition)\n",
    "\n",
    "def compute_split_measure(l, l0, l1, method):\n",
    "    p0 = probabilities(l0)\n",
    "    p1 = probabilities(l1)\n",
    "    p = probabilities(l)\n",
    "    return method(p) - (len(l0) * method(p0) + len(l1) * method(p1)) / (len(l))\n",
    "\n",
    "# TODO: Iterate over the possible splits, evaulating and saving the three criteria for each one\n",
    "# TODO: Then, Compute the split that each criterion favours and visualize them \n",
    "#       (e.g. with a histogram for each class and vertical lines to show the splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dijet data\n",
    "features = np.load('data/dijet_features_normalized.npy')\n",
    "labels = np.load('data/dijet_labels.npy')\n",
    "\n",
    "# TODO: define train, val and test splits as specified (make sure to shuffle the data before splitting it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# TODO: train a random forest classifier for each combination of specified hyperparameters \n",
    "#       and evaluate the performances on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for your preferred configuration, evaluate the performance of the best configuration on the test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
